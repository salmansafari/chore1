{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Practical No.: 2**\n","\n","# Building a natural language processing (NLP) model for sentiment analysis or text classification."],"metadata":{"id":"TwkE6Ctywkjl"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, Flatten, Dense\n","import numpy as np"],"metadata":{"id":"HwXLS3so1qNo"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"diNyFvbr1m2I"},"outputs":[],"source":["texts = [\n","    \"I love this product\",\n","    \"This is the worst movie\",\n","    \"I am so happy\",\n","    \"I hate this book\",\n","    \"What a great day\",\n","    \"I am very disappointed\"\n","]\n","\n","labels = [1, 0, 1, 0, 1, 0]  # 1 = Positive, 0 = Negative"]},{"cell_type":"code","source":["# Initialize tokenizer\n","tokenizer = Tokenizer(oov_token=\"<OOV>\")\n","tokenizer.fit_on_texts(texts)"],"metadata":{"id":"ZZyMigxm1zkQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert to sequences\n","sequences = tokenizer.texts_to_sequences(texts)\n","padded = pad_sequences(sequences, padding='post', maxlen=5)"],"metadata":{"id":"jcmfRbTX1333"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Vocabulary size\n","vocab_size = len(tokenizer.word_index) + 1"],"metadata":{"id":"2fRMVviw17jc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential([\n","    Embedding(input_dim=vocab_size, output_dim=8, input_length=5),\n","    Flatten(),\n","    Dense(6, activation='relu'),\n","    Dense(1, activation='sigmoid')\n","])\n","\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","#model.summary()"],"metadata":{"id":"RPzBfywn2CsY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert labels to NumPy array\n","labels = np.array(labels)"],"metadata":{"id":"rI1Xj6m02HL7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train\n","model.fit(padded, labels, epochs=50, verbose=1)  # Set verbose=1 if you want output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x4jojCQ12K76","executionInfo":{"status":"ok","timestamp":1755362412894,"user_tz":-330,"elapsed":5698,"user":{"displayName":"Virgin Fernando","userId":"08148199880652295383"}},"outputId":"bb601d84-d4e3-46a9-9ede-9f099861432f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.3333 - loss: 0.6996\n","Epoch 2/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.3333 - loss: 0.6972\n","Epoch 3/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.3333 - loss: 0.6950\n","Epoch 4/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.3333 - loss: 0.6929\n","Epoch 5/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6667 - loss: 0.6914\n","Epoch 6/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6667 - loss: 0.6899\n","Epoch 7/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.8333 - loss: 0.6885\n","Epoch 8/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.8333 - loss: 0.6871\n","Epoch 9/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.8333 - loss: 0.6858\n","Epoch 10/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.8333 - loss: 0.6845\n","Epoch 11/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.8333 - loss: 0.6831\n","Epoch 12/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.8333 - loss: 0.6816\n","Epoch 13/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.8333 - loss: 0.6802\n","Epoch 14/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 0.6787\n","Epoch 15/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.6773\n","Epoch 16/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 0.6759\n","Epoch 17/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.6744\n","Epoch 18/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.6730\n","Epoch 19/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.6716\n","Epoch 20/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.6702\n","Epoch 21/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.6688\n","Epoch 22/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.6673\n","Epoch 23/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.6657\n","Epoch 24/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.6642\n","Epoch 25/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.6628\n","Epoch 26/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8333 - loss: 0.6614\n","Epoch 27/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8333 - loss: 0.6599\n","Epoch 28/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8333 - loss: 0.6584\n","Epoch 29/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8333 - loss: 0.6567\n","Epoch 30/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.8333 - loss: 0.6551\n","Epoch 31/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8333 - loss: 0.6535\n","Epoch 32/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8333 - loss: 0.6518\n","Epoch 33/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8333 - loss: 0.6502\n","Epoch 34/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8333 - loss: 0.6485\n","Epoch 35/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8333 - loss: 0.6468\n","Epoch 36/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8333 - loss: 0.6451\n","Epoch 37/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8333 - loss: 0.6433\n","Epoch 38/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8333 - loss: 0.6415\n","Epoch 39/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8333 - loss: 0.6397\n","Epoch 40/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8333 - loss: 0.6378\n","Epoch 41/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8333 - loss: 0.6359\n","Epoch 42/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8333 - loss: 0.6340\n","Epoch 43/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8333 - loss: 0.6322\n","Epoch 44/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8333 - loss: 0.6302\n","Epoch 45/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8333 - loss: 0.6282\n","Epoch 46/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8333 - loss: 0.6262\n","Epoch 47/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.8333 - loss: 0.6241\n","Epoch 48/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8333 - loss: 0.6221\n","Epoch 49/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8333 - loss: 0.6199\n","Epoch 50/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8333 - loss: 0.6178\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7b8fc8b95b50>"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Test new sentences\n","test_texts = [\"so happy\", \"I hate this taste\", \"What a worst day\", \"Great movie\"]"],"metadata":{"id":"75rw2Q0w2Ybj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_texts = [\n","    \"I love this product\",\n","    \"worst movie\",\n","    \"I am so happy\",\n","    \"I hate this book\",\n","    \"great day\",\n","    \"I am very disappointed\"\n","]"],"metadata":{"id":"TnW15tsC4WVl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tokenize and pad\n","test_seq = tokenizer.texts_to_sequences(test_texts)\n","test_pad = pad_sequences(test_seq, maxlen=5, padding='post')"],"metadata":{"id":"feKneHho2bwm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions = model.predict(test_pad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9KEna9lh2dAG","executionInfo":{"status":"ok","timestamp":1755362421820,"user_tz":-330,"elapsed":59,"user":{"displayName":"Virgin Fernando","userId":"08148199880652295383"}},"outputId":"9e3990b3-12bd-455c-d084-462864ed32e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n"]}]},{"cell_type":"code","source":["for i, text in enumerate(test_texts):\n","    sentiment = \"Positive\" if predictions[i] > 0.51 else \"Negative\"\n","    print(f\"{text} → {sentiment} ({predictions[i][0]:.2f})\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T6rkzLnq2iig","executionInfo":{"status":"ok","timestamp":1755362457080,"user_tz":-330,"elapsed":10,"user":{"displayName":"Virgin Fernando","userId":"08148199880652295383"}},"outputId":"572b109f-3a8f-44ea-ff8c-a8dbdc33d878"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["I love this product → Positive (0.53)\n","worst movie → Negative (0.51)\n","I am so happy → Positive (0.56)\n","I hate this book → Negative (0.50)\n","great day → Positive (0.51)\n","I am very disappointed → Negative (0.45)\n"]}]},{"cell_type":"code","source":["for i, text in enumerate(test_texts):\n","    if predictions[i] > 0.51:\n","      sentiment = \"Positive\"\n","    else:\n","      sentiment = \"Negative\"\n","    print(f\"{text} → {sentiment} ({predictions[i][0]:.2f})\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SY8faG_43H65","executionInfo":{"status":"ok","timestamp":1755362470366,"user_tz":-330,"elapsed":5,"user":{"displayName":"Virgin Fernando","userId":"08148199880652295383"}},"outputId":"f8a9267d-77d6-480a-f750-f3059b9e8055"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["I love this product → Positive (0.53)\n","worst movie → Negative (0.51)\n","I am so happy → Positive (0.56)\n","I hate this book → Negative (0.50)\n","great day → Positive (0.51)\n","I am very disappointed → Negative (0.45)\n"]}]}]}