{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1XCkNZa31EFQB9pr6JjKC65NPmzbBQWTZ","timestamp":1755364956438}],"authorship_tag":"ABX9TyMLi3QIsLC3NxhzvPMC187Z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Practical No. 4**\n","\n","# **Developing a recommendation system using collaborative filtering or deep learning approaches.**"],"metadata":{"id":"86ixSNq76WhG"}},{"cell_type":"markdown","source":["Required Modules\n","\n","**Input** is used to define the entry point of a Keras model.\n","\n","***Used to instantiate a Keras tensor.***\n","\n","It creates a tensor placeholder that specifies the shape and data type of the inputs your model will receive.\n","\n","Input(shape=(1,)) to accept one user ID or one item ID at a time.\n","\n","These IDs are integers, and the input shape (1,) means a single number per example.\n","\n","-------------------------------------------------------------------------\n","\n","The **Embedding** layer maps discrete integer IDs to dense vectors — called embeddings.\n","\n","***Turns positive integers (indexes) into dense vectors of fixed size.***\n","\n","It’s like a lookup table: each integer index (like a user ID or item ID) is associated with a learnable vector.\n","\n","These vectors capture latent features or properties, learned during training.\n","\n","Raw IDs (like user 42 or item 7) have no numeric meaning by themselves.\n","\n","Embeddings turn these IDs into meaningful vectors of fixed size (e.g., 20 dimensions).\n","\n","This helps the model learn similarities and patterns between users or items.\n","\n","**input_dim** = number of unique IDs (e.g., total users or items)\n","\n","**output_dim** = size of the embedding vector (e.g., 20)\n","\n","When the model sees an ID, it returns the corresponding vector.\n","\n","\n","-------------------------------------------------------------------------\n","\n","The **Dot** layer computes the dot product (also called scalar product) between two tensors along specified axes.\n","\n","***Computes element-wise dot product of two tensors.***\n","\n","It’s a way to measure similarity or interaction between vectors.\n","\n","Often used in recommendation systems to compute the similarity between user and item embeddings.\n","\n","Eg. if two input tensors are provided\n","\n","User embedding vector: shape (batch_size, embedding_dim)\n","\n","Item embedding vector: shape (batch_size, embedding_dim)\n","\n","It computes the dot product along the embedding dimension for each batch item.\n","\n","The dot product between user and item embeddings estimates how well a user matches an item.\n","\n","Higher dot product = higher predicted rating or affinity.\n","\n","\n","-----------------------------------------------------------------------------\n","\n","The **Flatten** layer converts a multi-dimensional tensor into a 1D tensor by collapsing all dimensions except the batch size.\n","\n","It essentially reshapes the input from something like (batch_size, height, width, channels) to (batch_size, height * width * channels).\n","\n","This is useful to prepare data for fully connected (Dense) layers or for output layers that expect flat vectors.\n","\n","After computing the dot product between user and item embeddings, the output often has shape (batch_size, 1, 1).\n","\n","The Flatten layer converts this to (batch_size, 1) so it matches the shape expected by the loss function and output layer."],"metadata":{"id":"mOePvIQmRRUQ"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"bHwvUSX6BHp8","executionInfo":{"status":"ok","timestamp":1755365151501,"user_tz":-330,"elapsed":10627,"user":{"displayName":"Virgin Fernando","userId":"08148199880652295383"}}},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.layers import Input, Embedding, Dot, Flatten\n","from tensorflow.keras.models import Model"]},{"cell_type":"code","source":["# Sample user-item-rating data\n","ratings = np.array([\n","    [0, 0, 5.0],  # user 0 rated item 0 with 5\n","    [0, 1, 3.0],  # user 0 rated item 1 with 3\n","    [1, 0, 4.0],  # user 1 rated item 0 with 4\n","    [1, 2, 2.0],  # user 1 rated item 2 with 2\n","    [2, 1, 4.0],  # user 2 rated item 1 with 5\n","    [2, 2, 5.0],  # user 2 rated item 2 with 5\n","])"],"metadata":{"id":"LkM33jgUPwvG","executionInfo":{"status":"ok","timestamp":1755365171964,"user_tz":-330,"elapsed":54,"user":{"displayName":"Virgin Fernando","userId":"08148199880652295383"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["ratings"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n1kXt8LJXvs-","executionInfo":{"status":"ok","timestamp":1755365174024,"user_tz":-330,"elapsed":7,"user":{"displayName":"Virgin Fernando","userId":"08148199880652295383"}},"outputId":"6976954b-7610-447e-bce1-5893a802f8a5"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 5.],\n","       [0., 1., 3.],\n","       [1., 0., 4.],\n","       [1., 2., 2.],\n","       [2., 1., 4.],\n","       [2., 2., 5.]])"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# Number of users and items\n","num_users = int(np.max(ratings[:, 0])) + 1  # 3 users\n","num_items = int(np.max(ratings[:, 1])) + 1  # 3 items\n","embedding_size = 2"],"metadata":{"id":"6n2L4UyIX2xl","executionInfo":{"status":"ok","timestamp":1755365175328,"user_tz":-330,"elapsed":10,"user":{"displayName":"Virgin Fernando","userId":"08148199880652295383"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["NumPy slicing to extract a specific column from a 2D NumPy array named ratings.\n",": → selects all rows.\n","0 → selects the first column."],"metadata":{"id":"UyWqcLwSYSCy"}},{"cell_type":"code","source":["ratings[:, 0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o0dysSgLYAqm","executionInfo":{"status":"ok","timestamp":1755365177107,"user_tz":-330,"elapsed":25,"user":{"displayName":"Virgin Fernando","userId":"08148199880652295383"}},"outputId":"83f1a735-2a49-4136-a101-8253c4e4adfe"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 0., 1., 1., 2., 2.])"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["print(np.max(ratings[:, 0]),'\\n',int(np.max(ratings[:, 0])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2GU65J7DYRo-","executionInfo":{"status":"ok","timestamp":1755365178960,"user_tz":-330,"elapsed":24,"user":{"displayName":"Virgin Fernando","userId":"08148199880652295383"}},"outputId":"ba280136-55d6-43b3-d7aa-5f3eeaf7eeb8"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["2.0 \n"," 2\n"]}]},{"cell_type":"markdown","source":["creates an input layer in a Keras model that expects a single value as input\n","\n","shape=(1,) - the input is a 1-dimensional vector of size 1.\n","Eg. [3], [15], [102] (a single integer in a list).\n","\n","used in embedding-based models, where each ID is mapped to a vector.\n","\n","A user ID (e.g., 0, 1, 2, ...)\n","\n","An item ID (e.g., 0, 1, 2, ...)"],"metadata":{"id":"NSKVYA-GZ0GK"}},{"cell_type":"code","source":["# Inputs for user and item\n","user_input = Input(shape=(1,))\n","item_input = Input(shape=(1,))"],"metadata":{"id":"Y_vY_SWgZaMd","executionInfo":{"status":"ok","timestamp":1755365180806,"user_tz":-330,"elapsed":15,"user":{"displayName":"Virgin Fernando","userId":"08148199880652295383"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["setting the dimension of the latent (hidden) space in which both users and items will be embedded.\n","\n","embedding_size = 2\n","Each user and each item will be represented by a 2D vector (i.e., an array of 2 numbers).\n","\n","These vectors are learned during training.\n","\n","The dot product of the user and item vectors will be used to predict the rating.\n","\n","eg.\n","User 0 might be embedded as: [0.9, 0.2]\n","\n","Item 3 might be embedded as: [0.4, 0.7]\n","\n","The predicted rating = dot product\n","\n","(0.9 × 0.4) + (0.2 × 0.7) = 0.36 + 0.14 = 0.50\n"],"metadata":{"id":"pqbt-RZvasAn"}},{"cell_type":"markdown","source":["creates an embedding layer and applies it to the user_input.\n","to convert a user ID (an integer) into a dense vector (embedding) of fixed size.\n","\n","two embedding layers are created:\n","\n","One for users\n","\n","One for items\n","\n","Then their dot product to predict a rating or interaction score."],"metadata":{"id":"Bp0Sv84kb0qt"}},{"cell_type":"markdown","source":["eg.\n","\n","num_users = 5\n","embedding_size = 2\n","user_input = Input(shape=(1,))\n","\n","user_embedding = Embedding(input_dim=5, output_dim=2)(user_input)\n","\n","creates a user embedding matrix of shape (5, 2)\n","\n","\n","num_users = total users\n","\n","num_items = total items\n","\n","embedding_size = dimensionality of feature vectors (e.g., 20)\n","\n","Each user/item gets represented as a learned vector summarizing their preferences or characteristics.\n"],"metadata":{"id":"WtF9cYF5cPWy"}},{"cell_type":"code","source":["embedding_size = 2\n","user_embedding = Embedding(input_dim=num_users, output_dim=embedding_size)(user_input)\n","item_embedding = Embedding(input_dim=num_items, output_dim=embedding_size)(item_input)"],"metadata":{"id":"SjI37b6zagWs","executionInfo":{"status":"ok","timestamp":1755365184204,"user_tz":-330,"elapsed":79,"user":{"displayName":"Virgin Fernando","userId":"08148199880652295383"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["#eg. to understand embedding\n","\n","from tensorflow.keras.layers import Embedding\n","import tensorflow as tf\n","\n","# Suppose 5 unique items, embedding size 3\n","embedding_layer = Embedding(input_dim=5, output_dim=2)\n","\n","# Input IDs (batch of 2 items)\n","input_ids = tf.constant([[1], [3]])\n","\n","# Get embeddings\n","output_vectors = embedding_layer(input_ids)\n","\n","print(output_vectors)\n","\n","\n","#creates 2 samples, each with a 1-length sequence, each mapped to a 3D vector."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fXzt8vzJchh-","executionInfo":{"status":"ok","timestamp":1755365190550,"user_tz":-330,"elapsed":60,"user":{"displayName":"Virgin Fernando","userId":"08148199880652295383"}},"outputId":"0a1a5f6e-04b9-4be4-d67a-2175828edcf9"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[[-0.0037593   0.02323277]]\n","\n"," [[ 0.01436334 -0.01565754]]], shape=(2, 1, 2), dtype=float32)\n"]}]},{"cell_type":"markdown","source":["axes=2 - compute the dot product along the last axis (the embedding dimension) -- the one with the highest index — the last dimension of the shape..\n","\n","It performs the dot product between the user and item vectors for each sample in the batch.\n","\n","Output shape - (batch_size, 1, 1) — a single dot product score per user-item pair."],"metadata":{"id":"S_IB0iEEfb6-"}},{"cell_type":"code","source":["# Dot product of user and item embeddings\n","dot_product = Dot(axes=2)([user_embedding, item_embedding])"],"metadata":{"id":"cizeVPeQcxwA","executionInfo":{"status":"ok","timestamp":1755365192725,"user_tz":-330,"elapsed":20,"user":{"displayName":"Virgin Fernando","userId":"08148199880652295383"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["#Eg. to understand dot\n","\n","user_vector  = [0.2, 0.5]\n","item_vector  = [0.4, 0.7]\n","#dot_product  = 0.2*0.4 + 0.5*0.7 = 0.08 + 0.35 = 0.43\n","\n","embedding_size=2\n","predicted_rating = sum(user_vector[i] * item_vector[i] for i in range(embedding_size))\n","print(predicted_rating)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lYrA2fb3eSN6","executionInfo":{"status":"ok","timestamp":1755365193897,"user_tz":-330,"elapsed":227,"user":{"displayName":"Virgin Fernando","userId":"08148199880652295383"}},"outputId":"888a405d-5d23-4acf-f611-9e498a6f9cb2"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["0.43\n"]}]},{"cell_type":"markdown","source":["flattens the output of the previous Dot layer — it removes extra dimensions so that the output becomes a 1D tensor (vector) for each input pair.\n","\n","output of the Dot layer is typically a 3D tensor with shape\n","\n","Eg.\n","(batch_size, 1, 1)\n","Each prediction (dot product) is wrapped inside two singleton dimensions.\n","\n","[[[4.2]],\n"," [[3.8]],\n"," [[2.5]]]\n","\n","this shape is not convenient for\n","\n","Returning predictions\n","\n","Comparing with true values (which are 1D)\n","\n","Plotting or evaluating with metrics\n","\n","Flatten()\n","\n","[4.2, 3.8, 2.5]  # shape: (batch_size,)\n","\n"],"metadata":{"id":"Mp8A882rim2t"}},{"cell_type":"code","source":["# Flatten the result\n","dot_product = Flatten()(dot_product)"],"metadata":{"id":"v7He6Lkrh2dn","executionInfo":{"status":"ok","timestamp":1755365197808,"user_tz":-330,"elapsed":15,"user":{"displayName":"Virgin Fernando","userId":"08148199880652295383"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["creates a Keras model\n","\n","Takes two inputs:\n","\n","user_input: a single user ID\n","\n","item_input: a single item ID\n","\n","Outputs:\n","\n","dot_product: the predicted rating from the dot product of user and item embeddings\n","\n","matrix factorization method, needs both a user ID and an item ID to make a prediction\n","\n","user_input --> user embedding layer\n","item_input --> item embedding layer\n","These embeddings are then combined (via Dot) and flattened to produce the predicted rating.\n","\n"],"metadata":{"id":"RnSv4TRekKC0"}},{"cell_type":"code","source":["# Define the model\n","model = Model(inputs=[user_input, item_input], outputs=dot_product)"],"metadata":{"id":"oAoGTDY2jV5G","executionInfo":{"status":"ok","timestamp":1755365199557,"user_tz":-330,"elapsed":19,"user":{"displayName":"Virgin Fernando","userId":"08148199880652295383"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["Adam is a optimization algorithm that adjusts the model's weights to minimize the loss during training.\n","\n","MSE (Mean Squared Error) calculates the average of the squares of the differences between the predicted ratings and the true ratings.\n","![mse.png](data:image/png;base64,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)\n","\n","Used in regression problems\n","\n","predicting continuous ratings in recommender systems."],"metadata":{"id":"Ohu0KUL-k8dy"}},{"cell_type":"markdown","source":["The optimizer determines how the model learns.\n","\n","The loss function tells the model what to minimize during training (how far off the predictions are from actual values)."],"metadata":{"id":"2mGkIcQwlgmC"}},{"cell_type":"code","source":["model.compile(optimizer='adam', loss='mse')"],"metadata":{"id":"B6NcU5yhjpkt","executionInfo":{"status":"ok","timestamp":1755365202154,"user_tz":-330,"elapsed":28,"user":{"displayName":"Virgin Fernando","userId":"08148199880652295383"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Training data\n","X_users = ratings[:, 0].astype('int32')\n","X_items = ratings[:, 1].astype('int32')\n","y_ratings = ratings[:, 2].astype('float32')"],"metadata":{"id":"tUL7Bmu-l69F","executionInfo":{"status":"ok","timestamp":1755365202877,"user_tz":-330,"elapsed":2,"user":{"displayName":"Virgin Fernando","userId":"08148199880652295383"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["X_users"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ND2uzWLl_uH","executionInfo":{"status":"ok","timestamp":1755365204755,"user_tz":-330,"elapsed":226,"user":{"displayName":"Virgin Fernando","userId":"08148199880652295383"}},"outputId":"bdbfe7d0-833e-4634-8a38-6226d7364613"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 1, 1, 2, 2], dtype=int32)"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["X_items"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lWHMlbLNmD09","executionInfo":{"status":"ok","timestamp":1755365205578,"user_tz":-330,"elapsed":13,"user":{"displayName":"Virgin Fernando","userId":"08148199880652295383"}},"outputId":"18b2eedb-c94b-42b0-e67c-fedc1d7ba196"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1, 0, 2, 1, 2], dtype=int32)"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["y_ratings"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xn1uQHajmGa7","executionInfo":{"status":"ok","timestamp":1755365206700,"user_tz":-330,"elapsed":7,"user":{"displayName":"Virgin Fernando","userId":"08148199880652295383"}},"outputId":"864b2103-695b-4a8a-bcb5-55358f425061"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([5., 3., 4., 2., 4., 5.], dtype=float32)"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["# Train the model\n","model.fit([X_users, X_items], y_ratings, epochs=100, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TYt1nrEpmJz0","executionInfo":{"status":"ok","timestamp":1755365215765,"user_tz":-330,"elapsed":7287,"user":{"displayName":"Virgin Fernando","userId":"08148199880652295383"}},"outputId":"a1346db8-50a3-43c6-dbab-613b05b920dd"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 15.8359\n","Epoch 2/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 15.8352\n","Epoch 3/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 15.8346\n","Epoch 4/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 15.8340\n","Epoch 5/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 15.8334\n","Epoch 6/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 15.8328\n","Epoch 7/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 15.8322\n","Epoch 8/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 15.8316\n","Epoch 9/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 15.8310\n","Epoch 10/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 15.8304\n","Epoch 11/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 15.8298\n","Epoch 12/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 15.8292\n","Epoch 13/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 15.8286\n","Epoch 14/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 15.8279\n","Epoch 15/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 15.8273\n","Epoch 16/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 15.8266\n","Epoch 17/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 15.8259\n","Epoch 18/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 15.8252\n","Epoch 19/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 15.8244\n","Epoch 20/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 15.8236\n","Epoch 21/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 15.8228\n","Epoch 22/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 15.8220\n","Epoch 23/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 15.8211\n","Epoch 24/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 15.8201\n","Epoch 25/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 15.8192\n","Epoch 26/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 15.8182\n","Epoch 27/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 15.8171\n","Epoch 28/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 15.8160\n","Epoch 29/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 15.8149\n","Epoch 30/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 15.8137\n","Epoch 31/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 15.8124\n","Epoch 32/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 15.8111\n","Epoch 33/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 15.8097\n","Epoch 34/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 15.8083\n","Epoch 35/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 15.8068\n","Epoch 36/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 15.8053\n","Epoch 37/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 15.8037\n","Epoch 38/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 15.8021\n","Epoch 39/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 15.8003\n","Epoch 40/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 15.7986\n","Epoch 41/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 15.7967\n","Epoch 42/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 15.7948\n","Epoch 43/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 15.7928\n","Epoch 44/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 15.7907\n","Epoch 45/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 15.7886\n","Epoch 46/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 15.7864\n","Epoch 47/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 15.7841\n","Epoch 48/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 15.7817\n","Epoch 49/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 15.7793\n","Epoch 50/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 15.7768\n","Epoch 51/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 15.7742\n","Epoch 52/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 15.7715\n","Epoch 53/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 15.7687\n","Epoch 54/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 15.7659\n","Epoch 55/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 15.7630\n","Epoch 56/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 15.7599\n","Epoch 57/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 15.7569\n","Epoch 58/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 15.7537\n","Epoch 59/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 15.7504\n","Epoch 60/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 15.7470\n","Epoch 61/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 15.7436\n","Epoch 62/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 15.7400\n","Epoch 63/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 15.7364\n","Epoch 64/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 15.7327\n","Epoch 65/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 15.7289\n","Epoch 66/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 15.7249\n","Epoch 67/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 15.7209\n","Epoch 68/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 15.7168\n","Epoch 69/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 15.7126\n","Epoch 70/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 15.7083\n","Epoch 71/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 15.7039\n","Epoch 72/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 15.6994\n","Epoch 73/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 15.6948\n","Epoch 74/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 15.6901\n","Epoch 75/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 15.6853\n","Epoch 76/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 15.6804\n","Epoch 77/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 15.6754\n","Epoch 78/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 15.6703\n","Epoch 79/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 15.6651\n","Epoch 80/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 15.6598\n","Epoch 81/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 15.6543\n","Epoch 82/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 15.6488\n","Epoch 83/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 15.6432\n","Epoch 84/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 15.6374\n","Epoch 85/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 15.6315\n","Epoch 86/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 15.6256\n","Epoch 87/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 15.6195\n","Epoch 88/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 15.6133\n","Epoch 89/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 15.6070\n","Epoch 90/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 15.6005\n","Epoch 91/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 15.5940\n","Epoch 92/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 15.5873\n","Epoch 93/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 15.5805\n","Epoch 94/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 15.5736\n","Epoch 95/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 15.5666\n","Epoch 96/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 15.5595\n","Epoch 97/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 15.5522\n","Epoch 98/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 15.5449\n","Epoch 99/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 15.5373\n","Epoch 100/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 15.5297\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x79a3ae43a350>"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["# Predict a rating for user 0 on item 2\n","user_id = np.array([0])\n","item_id = np.array([2])\n","predicted = model.predict([user_id, item_id])\n","print(f\"Predicted rating for user 0 on item 2: {predicted[0].item():.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JtQdQYsymb1y","executionInfo":{"status":"ok","timestamp":1755365218050,"user_tz":-330,"elapsed":161,"user":{"displayName":"Virgin Fernando","userId":"08148199880652295383"}},"outputId":"97cb6662-af51-49bb-ef97-36c39e544f2d"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n","Predicted rating for user 0 on item 2: 0.03\n"]}]},{"cell_type":"markdown","source":["User Ids   |    Item Ids    |   Ratings\n","\n","0          |       2        |      ?\n","\n","1          |       0        |      ?\n","\n","2          |       1        |      ?\n"],"metadata":{"id":"b6W0E1nini5c"}},{"cell_type":"code","source":["# Predict for multiple user-item pairs\n","user_ids = np.array([0, 1, 2])\n","item_ids = np.array([2, 0, 1])\n","predicted_batch = model.predict([user_ids, item_ids])\n","for u, i, p in zip(user_ids, item_ids, predicted_batch):\n","    print(f\"Predicted rating for user {u} on item {i}: {p.item():.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yUar-_kfmjqA","executionInfo":{"status":"ok","timestamp":1755365221426,"user_tz":-330,"elapsed":236,"user":{"displayName":"Virgin Fernando","userId":"08148199880652295383"}},"outputId":"a4e0d3fd-abbd-4c07-c1d0-7a5650ee8095"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step\n","Predicted rating for user 0 on item 2: 0.03\n","Predicted rating for user 1 on item 0: 0.03\n","Predicted rating for user 2 on item 1: 0.05\n"]}]},{"cell_type":"code","source":["ratings"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R9EGghHznCgd","executionInfo":{"status":"ok","timestamp":1755365224077,"user_tz":-330,"elapsed":6,"user":{"displayName":"Virgin Fernando","userId":"08148199880652295383"}},"outputId":"736e363a-226d-472b-de41-3ad5450898f7"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 5.],\n","       [0., 1., 3.],\n","       [1., 0., 4.],\n","       [1., 2., 2.],\n","       [2., 1., 4.],\n","       [2., 2., 5.]])"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["zip combines three lists or arrays into one iterable of tuples.\n","\n","Each tuple will contain:\n","\n","One user ID\n","\n","One item ID\n","\n","One predicted rating"],"metadata":{"id":"DksDlgXepWD9"}},{"cell_type":"code","source":["# Predict for multiple user-item pairs\n","user_ids = np.array([0, 1, 2])\n","item_ids = np.array([0, 2, 1])\n","predicted_batch = model.predict([user_ids, item_ids])\n","for u, i, p in zip(user_ids, item_ids, predicted_batch):\n","    print(f\" User {u} - item {i} - Predicted rating : {p.item():.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tyvRRHhjnKlO","executionInfo":{"status":"ok","timestamp":1755365227009,"user_tz":-330,"elapsed":102,"user":{"displayName":"Virgin Fernando","userId":"08148199880652295383"}},"outputId":"4a153968-8ff8-4525-bca4-fbeaf439725a"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n"," User 0 - item 0 - Predicted rating : 0.03\n"," User 1 - item 2 - Predicted rating : 0.04\n"," User 2 - item 1 - Predicted rating : 0.05\n"]}]}]}